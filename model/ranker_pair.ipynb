{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4952,"status":"ok","timestamp":1701619837394,"user":{"displayName":"Zhen Wu","userId":"18428603457540150845"},"user_tz":300},"id":"v7uX8sWKqZAk","outputId":"26baecd6-7d8a-47b0-a83f-d951c82bc377"},"outputs":[],"source":["!pip install textstat -q"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28613,"status":"ok","timestamp":1701619886084,"user":{"displayName":"Zhen Wu","userId":"18428603457540150845"},"user_tz":300},"id":"WiS9enYTsIPB","outputId":"f40cde5b-59bc-4383-ce9e-75519d9e8e02"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bfYqinsYO5R3"},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","from torchvision import models, transforms\n","from transformers import BertTokenizer, VisualBertForPreTraining\n","from PIL import Image\n","from tqdm import tqdm\n","import requests\n","from io import BytesIO\n","import json\n","import os\n","import random\n","import gc\n","import h5py\n","import pickle\n","import numpy as np\n","import time"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":226,"referenced_widgets":["3e670a10f5fe4e338cc5729bd9dc3946","8e520c7db67a4e6a8158b163b48b4599","7dcd163b5c5946c38594a54e526b10d4","c4b54657d6df4273a6b376103c760343","d4c14cd4695e48b099387d0ad649eb7c","6a6a005e175e41d4afbc47361b68cb0d","bd4c08f2ea8c48079136be3e0fea97b0","607079ce75e44d15b7a9811540d33d90","772fd4105090451d8febd63b869da017","b45142440a844f1794d2d05165af25f7","74b30e458a28438ca2b57889d738e36f","0082bb0c3825477fa2cb3ab570e6ab45","02932acfc4274a21a1483a8919ad6c96","aae03e38e64b4f8b95f1fdf764790228","294e3c8a92094455b622d14b3912445f","174b933b46424a6d911e5e797968490a","be2084d20826468ca9773721539d6759","a2c52808294e4c09bb3df7e5109b0818","916591a48c254473bb754d7de51ff9d1","aaac2498fd264f6b9e618fce997d8ddb","7bddbabb479547a48233420c64a50a90","31886b4a53ef4eb2a6e26a2f249f9e27"]},"executionInfo":{"elapsed":716882,"status":"ok","timestamp":1701621002204,"user":{"displayName":"Zhen Wu","userId":"18428603457540150845"},"user_tz":300},"id":"mBzFxlmNOLKY","outputId":"39c44dfb-b586-426c-938c-3d6d39430a02"},"outputs":[],"source":["seed = 42\n","\n","def request_image(url, transform):\n","    rsp = requests.get(url, stream=True)\n","    img = Image.open(BytesIO(rsp.content)).convert('RGB')\n","    return transform(img)\n","\n","def load_csv_dataset(file_path, image_size=(224, 224)):\n","    df = pd.read_csv(file_path, nrows=2400)\n","    transform = transforms.Compose([transforms.Resize(image_size), transforms.ToTensor()])\n","    processed_data = []\n","\n","    for _, row in tqdm(df.iterrows(), total=df.shape[0]):\n","        story1 = row['sent1']\n","        story2 = row['sent2']\n","        label = row['label']\n","\n","        # Parse the URL field which is in string representation of list\n","        urls = json.loads(row['url'].replace(\"'\", '\"'))\n","\n","        img_tensors = []\n","        for url in urls:\n","            try:\n","                img_tensors.append(request_image(url, transform))\n","            except Exception as e:\n","                # print(f\"Error downloading image: {e}\")\n","                continue\n","\n","        if len(img_tensors) == 0:\n","            continue\n","\n","        img_tensor = torch.stack(img_tensors)\n","\n","        processed_data.append({'image': img_tensor, 'story1': story1, 'story2': story2, 'label': label})\n","\n","    return processed_data\n","\n","def collate_fn(batch):\n","    # Pad the visual embeddings to have the same sequence length\n","    image_features = pad_sequence([item['visual_embeds'] for item in batch], batch_first=True)\n","\n","    # Get the maximum sequence length for visual_attention_mask\n","    max_seq_length = max(item['visual_attention_mask'].shape[1] for item in batch)\n","\n","    # Pad the visual_attention_mask tensors\n","    visual_attention_mask = [torch.cat([item['visual_attention_mask'], torch.zeros(item['visual_attention_mask'].shape[0], max_seq_length - item['visual_attention_mask'].shape[1])], dim=1) for item in batch]\n","\n","    # Similarly, you can pad other sequences if necessary.\n","    # Stack other values\n","    input_ids_1 = torch.stack([item['input_ids_1'] for item in batch])\n","    attention_mask_1 = torch.stack([item['attention_mask_1'] for item in batch])\n","    visual_attention_mask = torch.stack(visual_attention_mask)\n","    ranker_gap = torch.tensor([item['ranker_gap'] for item in batch])\n","\n","    return {\n","        'input_ids_1': input_ids_1,\n","        'attention_mask_1': attention_mask_1,\n","        'visual_embeds': image_features,\n","        'visual_attention_mask': visual_attention_mask,\n","        'ranker_gap': ranker_gap\n","    }\n","\n","\n","# Custom Dataset class\n","class RankingDataset(Dataset):\n","    def __init__(self, data, tokenizer, resnet_model, max_length=512, mask_probability=0.15):\n","        self.data = data\n","        self.tokenizer = tokenizer\n","        self.resnet_model = resnet_model\n","        self.max_length = max_length\n","        self.mask_probability = mask_probability\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        item = self.data[idx]\n","\n","        # Process image\n","        image_feature_list = []\n","        # Extract features using ResNet\n","        for image in item['image']:\n","            with torch.no_grad():\n","                # Inside the __getitem__ method\n","                image_features = self.resnet_model(image.unsqueeze(0))\n","                # print(\"Shape after ResNet:\", image_features.shape)\n","\n","                image_features = image_features.view(image_features.size(0), -1)\n","                # print(\"Shape after flattening:\", image_features.shape)\n","\n","                image_feature_list.append(image_features)\n","                #image_features = self.projection(image_features)\n","                #print(\"Shape after projection:\", image_features.shape)\n","\n","        image_features = torch.cat(image_feature_list, dim=0)\n","\n","        # Process text\n","        story1 = item['story1']\n","        story2 = item['story2']\n","\n","        combined_input = story1 + ' [SEP] ' + story2\n","\n","        # Tokenize text and prepare inputs for VisualBERT\n","        inputs_1 = self.tokenizer.encode_plus(\n","            combined_input,\n","            add_special_tokens=True,\n","            max_length=self.max_length,\n","            padding='max_length',\n","            truncation=True,\n","            return_tensors='pt'\n","        )\n","\n","        inputs_ids_1 = inputs_1['input_ids'].squeeze()\n","\n","        attention_mask_1 = inputs_1['attention_mask']\n","\n","        visual_attention_mask = torch.ones((image_features.size(0),), dtype=torch.long).unsqueeze(0)\n","\n","        ranker_gap = item['label']\n","\n","        return {\n","            'input_ids_1': inputs_ids_1,\n","            'attention_mask_1': attention_mask_1,\n","            'visual_embeds': image_features,\n","            'visual_attention_mask': visual_attention_mask,\n","            'ranker_gap': ranker_gap\n","        }\n","\n","# Initialize components\n","transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","resnet_model = models.resnet50(pretrained=True)\n","resnet_model = nn.Sequential(*list(resnet_model.children())[:-1])\n","resnet_model.eval()\n","\n","print(\"Components initialized.\")\n","\n","# Load the dataset\n","print(\"Loading dataset...\")\n","\n","start = time.time()\n","\n","loaded_data = []\n","\n","with h5py.File('/content/drive/MyDrive/Colab Notebooks/project/VHED_url.hdf5', 'r') as f:\n","    for group_key in f:\n","        group = f[group_key]\n","        item = {}\n","        for key in group:\n","            # Read the pickled data\n","            pickled_data = group[key][()].tobytes()\n","            # Deserialize using pickle\n","            item[key] = pickle.loads(pickled_data)\n","        loaded_data.append(item)\n","\n","end = time.time()\n","\n","print(f'Loaded {len(loaded_data)} items in {end - start} seconds')\n","\n","# ranking_data = load_csv_dataset('/content/drive/MyDrive/Colab Notebooks/project/VHED_url.csv')\n","DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# ind = int(len(ranking_data) * 0.2)\n","# sub_loaded_data = ranking_data[:ind]\n","sub_loaded_data = loaded_data\n","\n","random.seed(seed)\n","\n","random.shuffle(sub_loaded_data)\n","\n","train_data_ind = int(0.6 * len(sub_loaded_data))\n","val_data_ind = int(0.8 * len(sub_loaded_data))\n","\n","train_data = sub_loaded_data[:train_data_ind]\n","val_data = sub_loaded_data[train_data_ind:val_data_ind]\n","test_data = sub_loaded_data[val_data_ind:]\n","\n","train_dataset = RankingDataset(train_data, tokenizer, resnet_model)\n","val_dataset = RankingDataset(val_data, tokenizer, resnet_model)\n","test_dataset = RankingDataset(test_data, tokenizer, resnet_model)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn, num_workers=8)\n","val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn, num_workers=8)\n","test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn, num_workers=8)\n","\n","# Training loop\n","def train_ranker(model, dataloader, optimizer, criterion):\n","    model.train()\n","\n","    total_correct = 0\n","    total_sample = 0\n","\n","    for batch in tqdm(dataloader):\n","        input_ids_1 = batch['input_ids_1']\n","        attention_mask_1 = batch['attention_mask_1']\n","        visual_embeds = batch['visual_embeds']\n","        visual_attention_mask = batch['visual_attention_mask']\n","        ranking_gap = batch['ranker_gap'].float()\n","\n","        # move everything to device\n","        input_ids_1 = input_ids_1.to(DEVICE)\n","        attention_mask_1 = attention_mask_1.to(DEVICE)\n","        visual_embeds = visual_embeds.to(DEVICE)\n","        visual_attention_mask = visual_attention_mask.to(DEVICE)\n","        ranking_gap = ranking_gap.to(DEVICE)\n","\n","        # Forward pass and loss computation for both story inputs\n","        outputs_1 = model(\n","            input_ids=input_ids_1,\n","            visual_embeds=visual_embeds,\n","            attention_mask=attention_mask_1,  # Add this\n","            visual_attention_mask=visual_attention_mask,  # Add this\n","            output_hidden_states=True\n","        )\n","\n","        outputs_1 = model.dropout(outputs_1.hidden_states[-1][:, 0])\n","\n","        # Use the new ranking layer to predict the ranking gap\n","        ranking_prediction_1 = model.regression_layer(outputs_1)\n","        ranking_prediction = ranking_prediction_1.squeeze(-1)\n","\n","        # compute accuracy\n","        for i in range(len(ranking_prediction)):\n","            if ranking_prediction[i] > 0 and ranking_gap[i] > 0:\n","                total_correct += 1\n","            elif ranking_prediction[i] < 0 and ranking_gap[i] < 0:\n","                total_correct += 1\n","\n","        total_sample += ranking_prediction.shape[0]\n","\n","        ranking_prediction = ranking_prediction.to(DEVICE)\n","\n","        # Compute loss\n","        loss = criterion(ranking_prediction, ranking_gap)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    print(f\"Train Accuracy: {total_correct / total_sample}\")\n","    print(f\"Train Loss: {loss.item()}\")\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","def evaluate_ranker(model, dataloader, criterion):\n","    model.eval()\n","    total_correct = 0\n","    total_sample = 0\n","    total_loss = 0\n","    with torch.no_grad():\n","        for batch in tqdm(dataloader):\n","            input_ids_1 = batch['input_ids_1']\n","            attention_mask_1 = batch['attention_mask_1']\n","            visual_embeds = batch['visual_embeds']\n","            visual_attention_mask = batch['visual_attention_mask']\n","            ranking_gap = batch['ranker_gap'].float()\n","\n","            #\n","            input_ids_1 = input_ids_1.to(DEVICE)\n","            attention_mask_1 = attention_mask_1.to(DEVICE)\n","            visual_embeds = visual_embeds.to(DEVICE)\n","            visual_attention_mask = visual_attention_mask.to(DEVICE)\n","            ranking_gap = ranking_gap.to(DEVICE)\n","\n","            # Forward pass\n","            outputs1 = model(\n","                input_ids=input_ids_1,\n","                visual_embeds=visual_embeds,\n","                attention_mask=attention_mask_1,  # Add this\n","                visual_attention_mask=visual_attention_mask,\n","                output_hidden_states=True\n","            )\n","\n","            #\n","            ranking_prediction_1 = model.regression_layer(outputs1.hidden_states[-1][:, 0])\n","            ranking_prediction = ranking_prediction_1.squeeze(-1)\n","\n","            ranking_prediction = ranking_prediction.to(DEVICE)\n","            #\n","            loss = criterion(ranking_prediction, ranking_gap)\n","            total_loss += loss.item()\n","            #\n","            for i in range(len(ranking_prediction)):\n","                if ranking_prediction[i] > 0 and ranking_gap[i] > 0:\n","                    total_correct += 1\n","\n","                elif ranking_prediction[i] < 0 and ranking_gap[i] < 0:\n","                    total_correct += 1\n","            total_sample += ranking_prediction.shape[0]\n","    print(f\"Val Accuracy: {total_correct / total_sample}\")\n","    print(f\"Val Loss: {total_loss / total_sample}\")\n","\n","    return total_correct / total_sample\n","\n","# Load your pre-trained VisualBert model\n","model = VisualBertForPreTraining.from_pretrained('uclanlp/visualbert-vqa-coco-pre')\n","model.load_state_dict(torch.load('/content/drive/MyDrive/Project/VIST-Inspector-main/model/epoch_1.pt'))\n","model.eval()  # Make sure the model is in evaluation mode\n","\n","# Modify model for ranking task\n","# Add a linear layer to model for regression task\n","model.regression_layer = nn.Linear(model.config.hidden_size, 1)\n","\n","model.dropout = nn.Dropout(p=0.1)\n","\n","# Define optimizer and loss function for ranking\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-6, weight_decay=1e-5)\n","criterion = nn.MSELoss()\n","\n","model = model.to(DEVICE)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":21129301,"status":"error","timestamp":1701642584155,"user":{"displayName":"Zhen Wu","userId":"18428603457540150845"},"user_tz":300},"id":"8W3H3mYHOTz5","outputId":"dd584774-cda5-4510-d4dc-837fd8eb3853"},"outputs":[],"source":["num_epochs = 30\n","\n","save_path = '/content/drive/MyDrive/Colab Notebooks/project/subset'\n","\n","best_val_acc = 0\n","\n","for epoch in range(num_epochs):\n","    train_ranker(model, train_dataloader, optimizer, criterion)\n","    val_acc = evaluate_ranker(model, val_dataloader, criterion)\n","    print(f\"Epoch {epoch} complete.\")\n","    # Save the fine-tuned model\n","    if val_acc > best_val_acc:\n","        best_val_acc = val_acc\n","        torch.save(model.state_dict(), os.path.join(save_path, f'ranker_pair_no_ling_best.pt'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X-IRVL0-Wos9"},"outputs":[],"source":["def test_ranker(model, dataloader, criterion):\n","    model.eval()\n","    total_correct = 0\n","    total_sample = 0\n","    total_loss = 0\n","    results = []\n","    with torch.no_grad():\n","        for batch in tqdm(dataloader):\n","            input_ids_1 = batch['input_ids_1']\n","            attention_mask_1 = batch['attention_mask_1']\n","            visual_embeds = batch['visual_embeds']\n","            visual_attention_mask = batch['visual_attention_mask']\n","            ranking_gap = batch['ranker_gap'].float()\n","\n","            #\n","            input_ids_1 = input_ids_1.to(DEVICE)\n","            attention_mask_1 = attention_mask_1.to(DEVICE)\n","            visual_embeds = visual_embeds.to(DEVICE)\n","            visual_attention_mask = visual_attention_mask.to(DEVICE)\n","            ranking_gap = ranking_gap.to(DEVICE)\n","\n","            # Forward pass\n","            outputs1 = model(\n","                input_ids=input_ids_1,\n","                visual_embeds=visual_embeds,\n","                attention_mask=attention_mask_1,  # Add this\n","                visual_attention_mask=visual_attention_mask,\n","                output_hidden_states=True\n","            )\n","            #\n","            ranking_prediction_1 = model.regression_layer(outputs1.hidden_states[-1][:, 0])\n","            ranking_prediction = ranking_prediction_1.squeeze(-1)\n","\n","            results.extend(ranking_prediction.tolist())\n","\n","            ranking_prediction = ranking_prediction.to(DEVICE)\n","            #\n","            loss = criterion(ranking_prediction, ranking_gap)\n","            total_loss += loss.item()\n","            #\n","            for i in range(len(ranking_prediction)):\n","                if ranking_prediction[i] > 0 and ranking_gap[i] > 0:\n","                    total_correct += 1\n","\n","                elif ranking_prediction[i] < 0 and ranking_gap[i] < 0:\n","                    total_correct += 1\n","            total_sample += ranking_prediction.shape[0]\n","    print(f\"Test Accuracy: {total_correct / total_sample}\")\n","    print(f\"Test Loss: {total_loss / total_sample}\")\n","\n","    return results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P52VxQj3WL2a"},"outputs":[],"source":["finetuned_model = VisualBertForPreTraining.from_pretrained('uclanlp/visualbert-vqa-coco-pre')\n","\n","finetuned_model.regression_layer = nn.Linear(finetuned_model.config.hidden_size, 1)\n","\n","finetuned_model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/project/subset/ranker_pair_no_ling_best.pt'))\n","\n","finetuned_model = finetuned_model.to(DEVICE)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":471845,"status":"ok","timestamp":1701643145227,"user":{"displayName":"Zhen Wu","userId":"18428603457540150845"},"user_tz":300},"id":"IBmBE7SPW8kg","outputId":"07ed1558-f552-4567-d816-1e75c4bcdb38"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 632/632 [07:51<00:00,  1.34it/s]"]},{"name":"stdout","output_type":"stream","text":["Test Accuracy: 0.8816778789077958\n","Test Loss: 0.10837324555328637\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["results = test_ranker(finetuned_model, test_dataloader, criterion)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":323,"status":"ok","timestamp":1701643280221,"user":{"displayName":"Zhen Wu","userId":"18428603457540150845"},"user_tz":300},"id":"NNQxK-aJW_hL","outputId":"98d37c0b-189a-4db8-b1c4-29b2f7bee5c6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Done!\n"]}],"source":["import csv\n","\n","# write test dataloader column story1, story2, label and the above reults to csv\n","with open('/content/drive/MyDrive/Colab Notebooks/project/subset/ranker_no_ling_pair_test_results.csv', 'w') as f:\n","    writer = csv.writer(f)\n","\n","    writer.writerow(['story1', 'story2', 'label', 'prediction'])\n","\n","    data = test_dataloader.dataset.data\n","\n","    for i in range(len(data)):\n","        writer.writerow([data[i]['story1'], data[i]['story2'], data[i]['label'], results[i]])\n","\n","    f.close()\n","    print('Done!')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0082bb0c3825477fa2cb3ab570e6ab45":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_02932acfc4274a21a1483a8919ad6c96","IPY_MODEL_aae03e38e64b4f8b95f1fdf764790228","IPY_MODEL_294e3c8a92094455b622d14b3912445f"],"layout":"IPY_MODEL_174b933b46424a6d911e5e797968490a"}},"02932acfc4274a21a1483a8919ad6c96":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be2084d20826468ca9773721539d6759","placeholder":"​","style":"IPY_MODEL_a2c52808294e4c09bb3df7e5109b0818","value":"pytorch_model.bin: 100%"}},"174b933b46424a6d911e5e797968490a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"294e3c8a92094455b622d14b3912445f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7bddbabb479547a48233420c64a50a90","placeholder":"​","style":"IPY_MODEL_31886b4a53ef4eb2a6e26a2f249f9e27","value":" 448M/448M [00:01&lt;00:00, 386MB/s]"}},"31886b4a53ef4eb2a6e26a2f249f9e27":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e670a10f5fe4e338cc5729bd9dc3946":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8e520c7db67a4e6a8158b163b48b4599","IPY_MODEL_7dcd163b5c5946c38594a54e526b10d4","IPY_MODEL_c4b54657d6df4273a6b376103c760343"],"layout":"IPY_MODEL_d4c14cd4695e48b099387d0ad649eb7c"}},"607079ce75e44d15b7a9811540d33d90":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a6a005e175e41d4afbc47361b68cb0d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74b30e458a28438ca2b57889d738e36f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"772fd4105090451d8febd63b869da017":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7bddbabb479547a48233420c64a50a90":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7dcd163b5c5946c38594a54e526b10d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_607079ce75e44d15b7a9811540d33d90","max":631,"min":0,"orientation":"horizontal","style":"IPY_MODEL_772fd4105090451d8febd63b869da017","value":631}},"8e520c7db67a4e6a8158b163b48b4599":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a6a005e175e41d4afbc47361b68cb0d","placeholder":"​","style":"IPY_MODEL_bd4c08f2ea8c48079136be3e0fea97b0","value":"config.json: 100%"}},"916591a48c254473bb754d7de51ff9d1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2c52808294e4c09bb3df7e5109b0818":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aaac2498fd264f6b9e618fce997d8ddb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aae03e38e64b4f8b95f1fdf764790228":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_916591a48c254473bb754d7de51ff9d1","max":448356189,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aaac2498fd264f6b9e618fce997d8ddb","value":448356189}},"b45142440a844f1794d2d05165af25f7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd4c08f2ea8c48079136be3e0fea97b0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be2084d20826468ca9773721539d6759":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4b54657d6df4273a6b376103c760343":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b45142440a844f1794d2d05165af25f7","placeholder":"​","style":"IPY_MODEL_74b30e458a28438ca2b57889d738e36f","value":" 631/631 [00:00&lt;00:00, 57.2kB/s]"}},"d4c14cd4695e48b099387d0ad649eb7c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
